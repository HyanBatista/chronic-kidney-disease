{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage as ski\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    cohen_kappa_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tqdm.auto import tqdm\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"drsprg\"\n",
    "DATA_BASE_DIR = Path(f\"../data/processed/{DATASET_NAME}/\")\n",
    "DATASET = DATA_BASE_DIR / Path(\"data_list_export_120217.xlsx\")\n",
    "AVG_BLURRED_IMAGES = DATA_BASE_DIR / Path(\"artifacts/avg_blurred_images.pkl\")\n",
    "PREP_STUDIES = DATA_BASE_DIR / Path(\"artifacts/prep_studies.pkl\")\n",
    "\n",
    "# Experiment variables\n",
    "SEED = 42\n",
    "CV = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies = tuple(joblib.load(PREP_STUDIES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LBPEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"LBP encoder for image data.\"\"\"\n",
    "\n",
    "    def __init__(self, radius: int = 1, sampling_pixels: int = 106):\n",
    "        self.radius = radius\n",
    "        self.sampling_pixels = sampling_pixels\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"Extract the LBP from the images batch.\"\"\"\n",
    "        X = list(X)\n",
    "        cvt_imgs = [self._cvt(img) for img in X]\n",
    "        imgs_lbps = [self._get_lbp(img) for img in cvt_imgs]\n",
    "        imgs_hists = [self._get_hist(img_lbp) for img_lbp in imgs_lbps]\n",
    "        features = self._get_features(imgs_hists)\n",
    "        return features\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def _cvt(self, img):\n",
    "        if isinstance(img, float):\n",
    "            print(\"test\")\n",
    "        if len(img.shape) > 2:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            _, img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "        i_min = np.min(img)\n",
    "        i_max = np.max(img)\n",
    "        if i_max - i_min != 0:\n",
    "            img = (img - i_min) / (i_max - i_min)\n",
    "\n",
    "        img = img.astype(np.uint8)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def _get_lbp(self, img):\n",
    "        lbp = ski.feature.local_binary_pattern(\n",
    "            img, self.sampling_pixels, self.radius, method=\"uniform\"\n",
    "        )\n",
    "        return (img, lbp)\n",
    "\n",
    "    def _get_hist(self, img_lbp):\n",
    "        img, lbp = img_lbp\n",
    "        hist, _ = np.histogram(\n",
    "            lbp.ravel(),\n",
    "            bins=np.arange(0, self.sampling_pixels + 3),\n",
    "            range=(0, self.sampling_pixels + 2),\n",
    "        )\n",
    "        hist = hist.astype(\"float\")\n",
    "        hist /= hist.sum() + 1e-6\n",
    "        return img, hist\n",
    "\n",
    "    def _get_features(self, imgs_hists):\n",
    "        hists = [img_hist[1] for img_hist in imgs_hists]\n",
    "        features = []\n",
    "        for h in hists:\n",
    "            features.extend(h)\n",
    "        return hists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc96a823ed64db39931dedbf9bd04d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Studies:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples = [(([pi[0] for pi in study[0]]), study[1]) for study in tqdm(studies, desc=\"Studies\")]\n",
    "df = pd.DataFrame(data=samples, columns=[\"features\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b90f2eb83dd4a59961c0dedce917b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"features\"] = df[\"features\"].progress_apply(lambda images: np.mean(np.stack(images, axis=0), axis=0).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CVResults:\n",
    "    algo: str\n",
    "    encoder: str\n",
    "    test_acc: list[float]\n",
    "    test_macro_prec: list[float]\n",
    "    test_weighted_prec: list[float]\n",
    "    test_macro_recall: list[float]\n",
    "    test_weighted_recall: list[float]\n",
    "    test_macro_f1: list[float]\n",
    "    test_weighted_f1: list[float]\n",
    "\n",
    "\n",
    "def _create_lbp_pipeline(clf: BaseEstimator) -> Pipeline:\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"encoder\", LBPEncoder()),\n",
    "            (\"clf\", clf),\n",
    "        ]\n",
    "    )\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def _run_sklearn_cv(\n",
    "    clf: BaseEstimator | Pipeline,\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    cv: int,\n",
    "    random_state,\n",
    "    shuffle=True,\n",
    "):\n",
    "    \"\"\"Run the experiments using cross-validation.\"\"\"\n",
    "\n",
    "    ALGO_NAME_DICT = {\n",
    "        ExtraTreesClassifier: \"Extra Trees\",\n",
    "        DecisionTreeClassifier: \"Decision Tree\",\n",
    "        SVC: \"Support Vector\",\n",
    "        RandomForestClassifier: \"Random Forest\",\n",
    "        XGBClassifier: \"XGBoost\",\n",
    "        MLPClassifier: \"MLP\",\n",
    "    }\n",
    "\n",
    "    ENCODER_NAME_DICT = {\n",
    "        LBPEncoder: \"LBP\",\n",
    "        # ViTEncoder: \"ViT\",\n",
    "    }\n",
    "\n",
    "    # Generate split\n",
    "    skf = StratifiedKFold(n_splits=cv, random_state=random_state, shuffle=shuffle)\n",
    "    for train_index, test_index in skf.split(np.array(X), y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "    # Train model\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate model\n",
    "    y_pred = clf.predict(X_test)\n",
    "    cv_results = CVResults(\n",
    "        algo=ALGO_NAME_DICT[type(clf.named_steps[\"clf\"])],\n",
    "        encoder=ENCODER_NAME_DICT[type(clf.named_steps[\"encoder\"])],\n",
    "        test_acc=accuracy_score(y_test, y_pred),\n",
    "        test_macro_prec=precision_score(y_test, y_pred, average=\"macro\"),\n",
    "        test_weighted_prec=precision_score(y_test, y_pred, average=\"weighted\"),\n",
    "        test_macro_recall=recall_score(y_test, y_pred, average=\"macro\"),\n",
    "        test_weighted_recall=recall_score(y_test, y_pred, average=\"weighted\"),\n",
    "        test_macro_f1=f1_score(y_test, y_pred, average=\"macro\"),\n",
    "        test_weighted_f1=f1_score(y_test, y_pred, average=\"weighted\"),\n",
    "    )\n",
    "    return cv_results\n",
    "\n",
    "\n",
    "def run_experiments(\n",
    "    clfs: list[BaseEstimator],\n",
    "    studies: pd.DataFrame,\n",
    "    cv: int,\n",
    "    random_state,\n",
    ") -> dict[str, list[np.ndarray]]:\n",
    "    \"\"\"Run experiments.\"\"\"\n",
    "\n",
    "    lbp_cv_results = [\n",
    "        _run_sklearn_cv(\n",
    "            _create_lbp_pipeline(clf),\n",
    "            np.array(studies[\"features\"]),\n",
    "            np.array(studies[\"labels\"]),\n",
    "            cv=cv,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "        for clf in tqdm(clfs, desc=f\"Classifiers\")\n",
    "    ]\n",
    "\n",
    "    cv_result_list = [lbp_cv_results]\n",
    "\n",
    "    return cv_result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ee92b912b94802b31ca8ac830355bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifiers:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clfs = [\n",
    "    SVC(random_state=SEED),\n",
    "    RandomForestClassifier(random_state=SEED),\n",
    "    DecisionTreeClassifier(random_state=SEED),\n",
    "    ExtraTreesClassifier(random_state=SEED),\n",
    "    # XGBClassifier(\n",
    "    #     objective=\"multi:softprob\",\n",
    "    #     eval_metric=\"mlogloss\",\n",
    "    # ),\n",
    "    MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=SEED),\n",
    "]\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(action=\"ignore\", category=UndefinedMetricWarning)\n",
    "    cv_results_list = run_experiments(clfs, df, cv=CV, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo</th>\n",
       "      <th>encoder</th>\n",
       "      <th>acc</th>\n",
       "      <th>macro_prec</th>\n",
       "      <th>weighted_prec</th>\n",
       "      <th>macro_recall</th>\n",
       "      <th>weighted_recall</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>weighted_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Support Vector</td>\n",
       "      <td>LBP</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.37500</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>LBP</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.804762</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.78022</td>\n",
       "      <td>0.793407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>LBP</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.37500</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Extra Trees</td>\n",
       "      <td>LBP</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.82906</td>\n",
       "      <td>0.841026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP</td>\n",
       "      <td>LBP</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.37500</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             algo encoder   acc  macro_prec  weighted_prec  macro_recall  \\\n",
       "0  Support Vector     LBP  0.60    0.300000       0.360000      0.500000   \n",
       "1   Random Forest     LBP  0.80    0.809524       0.804762      0.770833   \n",
       "2   Decision Tree     LBP  0.40    0.375000       0.400000      0.375000   \n",
       "3     Extra Trees     LBP  0.85    0.900000       0.880000      0.812500   \n",
       "4             MLP     LBP  0.60    0.300000       0.360000      0.500000   \n",
       "\n",
       "   weighted_recall  macro_f1  weighted_f1  \n",
       "0             0.60   0.37500     0.450000  \n",
       "1             0.80   0.78022     0.793407  \n",
       "2             0.40   0.37500     0.400000  \n",
       "3             0.85   0.82906     0.841026  \n",
       "4             0.60   0.37500     0.450000  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scores_to_df(cv_results_list: list[list[CVResults]]) -> pd.DataFrame:\n",
    "    \"\"\"Transform the scores dictionary into a dataframe object.\"\"\"\n",
    "    data = []\n",
    "    for cv_results in cv_results_list:\n",
    "        for cv_result in cv_results:\n",
    "            data.append(\n",
    "                {\n",
    "                    \"algo\": cv_result.algo,\n",
    "                    \"encoder\": cv_result.encoder,\n",
    "                    \"acc\": np.mean(cv_result.test_acc),\n",
    "                    \"macro_prec\": np.mean(cv_result.test_macro_prec),\n",
    "                    \"weighted_prec\": np.mean(cv_result.test_weighted_prec),\n",
    "                    \"macro_recall\": np.mean(cv_result.test_macro_recall),\n",
    "                    \"weighted_recall\": np.mean(cv_result.test_weighted_recall),\n",
    "                    \"macro_f1\": np.mean(cv_result.test_macro_f1),\n",
    "                    \"weighted_f1\": np.mean(cv_result.test_weighted_f1),\n",
    "                }\n",
    "            )\n",
    "    df = pd.DataFrame(data=data)\n",
    "    return df\n",
    "\n",
    "scores_to_df(cv_results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ckd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
