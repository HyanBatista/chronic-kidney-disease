{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import joblib\n",
    "import mahotas as mh\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage as ski\n",
    "import torch\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from skimage import img_as_ubyte\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import ViTImageProcessor, ViTModel\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"drsprg\"\n",
    "DATA_BASE_DIR = Path(f\"../data/processed/{DATASET_NAME}/\")\n",
    "PREP_STUDIES = DATA_BASE_DIR / Path(\"artifacts/prep_studies.pkl\")\n",
    "\n",
    "# Experiment variables\n",
    "SEED = 42\n",
    "CV = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies = tuple(joblib.load(PREP_STUDIES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = studies[0][0][0][0]\n",
    "\n",
    "# image = img\n",
    "# extract_zernike_moments(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZernikeMomentsEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Extracts Zernike Moments from a binary or grayscale image.\n",
    "\n",
    "    Attributes:\n",
    "    ----------\n",
    "    radius : int, optional\n",
    "        The radius of the circle to compute the moments (default is 21).\n",
    "    degree : int, optional\n",
    "        The maximum degree for Zernike moments (default is 8).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, radius: int = 21, degree: int = 8) -> None:\n",
    "        self.radius = radius\n",
    "        self.degree = degree\n",
    "\n",
    "    def transform(self, X, y=None) -> np.ndarray:\n",
    "        X = list(X)\n",
    "        X = np.array([self._extract(x) for x in X])\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def _extract(self, image: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        # Gray image\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Ensure the image is binary or grayscale\n",
    "        if len(image.shape) > 2:\n",
    "            raise ValueError(\"Input image should be 2D (grayscale or binary).\")\n",
    "\n",
    "        # Normalize the image if it's not binary (convert it to binary)\n",
    "        binary_image = (image > image.mean()).astype(np.uint8)\n",
    "\n",
    "        # Calculate Zernike Moments using the mahotas library\n",
    "        moments = mh.features.zernike_moments(binary_image, self.radius, self.degree)\n",
    "\n",
    "        return moments\n",
    "\n",
    "\n",
    "class GLCMEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    A class to represent an GLCM encoder.\n",
    "\n",
    "    Atributes:\n",
    "    - distances: List of pixel pair distance offsets for GLCM computation.\n",
    "    - angles: List of angles in radians for GLCM computation.\n",
    "    - levels: The number of gray levels for the GLCM (default is 256).\n",
    "    - symmetric: If True, GLCM matrix will be symmetric.\n",
    "    - normed: If True, the GLCM matrix will be normalized.\n",
    "\n",
    "    Methods:\n",
    "    - transform(): Extracts the GLCM features (contrast, correlation, energy, homogeneity) from an image.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        distances: list[int] = [1],\n",
    "        angles: list[int] = [0],\n",
    "        levels: int = 256,\n",
    "        symmetric: bool = True,\n",
    "        normed: bool = True,\n",
    "    ):\n",
    "        self.distances = distances\n",
    "        self.angles = angles\n",
    "        self.levels = levels\n",
    "        self.symmetric = symmetric\n",
    "        self.normed = normed\n",
    "\n",
    "    def transform(self, X, y=None) -> np.ndarray:\n",
    "        X = list(X)\n",
    "        X = np.array([self._extract(x) for x in X])\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def _extract(self, image: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        # Gray image\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Convert image to 8-bit unsigned integer type, if needed\n",
    "        image = img_as_ubyte(image)\n",
    "\n",
    "        # Compute the GLCM matrix\n",
    "        glcm = graycomatrix(\n",
    "            image,\n",
    "            distances=self.distances,\n",
    "            angles=self.angles,\n",
    "            levels=self.levels,\n",
    "            symmetric=self.symmetric,\n",
    "            normed=self.normed,\n",
    "        )\n",
    "\n",
    "        # Extract GLCM properties (features)\n",
    "        contrast = graycoprops(glcm, \"contrast\").mean()\n",
    "        correlation = graycoprops(glcm, \"correlation\").mean()\n",
    "        energy = graycoprops(glcm, \"energy\").mean()\n",
    "        homogeneity = graycoprops(glcm, \"homogeneity\").mean()\n",
    "\n",
    "        # Return the features as a dictionary\n",
    "        features = np.array([contrast, correlation, energy, homogeneity])\n",
    "\n",
    "        return features\n",
    "\n",
    "\n",
    "class LBPEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"LBP encoder for image data.\"\"\"\n",
    "\n",
    "    def __init__(self, radius: int = 1, sampling_pixels: int = 106):\n",
    "        self.radius = radius\n",
    "        self.sampling_pixels = sampling_pixels\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"Extract the LBP from the images batch.\"\"\"\n",
    "        X = list(X)\n",
    "        cvt_imgs = [self._cvt(img) for img in X]\n",
    "        imgs_lbps = [self._get_lbp(img) for img in cvt_imgs]\n",
    "        imgs_hists = [self._get_hist(img_lbp) for img_lbp in imgs_lbps]\n",
    "        features = self._get_features(imgs_hists)\n",
    "        return features\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def _cvt(self, img):\n",
    "        if isinstance(img, float):\n",
    "            print(\"test\")\n",
    "        if len(img.shape) > 2:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            _, img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "        i_min = np.min(img)\n",
    "        i_max = np.max(img)\n",
    "        if i_max - i_min != 0:\n",
    "            img = (img - i_min) / (i_max - i_min)\n",
    "\n",
    "        img = img.astype(np.uint8)\n",
    "\n",
    "        return img\n",
    "\n",
    "    def _get_lbp(self, img):\n",
    "        lbp = ski.feature.local_binary_pattern(\n",
    "            img, self.sampling_pixels, self.radius, method=\"uniform\"\n",
    "        )\n",
    "        return (img, lbp)\n",
    "\n",
    "    def _get_hist(self, img_lbp):\n",
    "        img, lbp = img_lbp\n",
    "        hist, _ = np.histogram(\n",
    "            lbp.ravel(),\n",
    "            bins=np.arange(0, self.sampling_pixels + 3),\n",
    "            range=(0, self.sampling_pixels + 2),\n",
    "        )\n",
    "        hist = hist.astype(\"float\")\n",
    "        hist /= hist.sum() + 1e-6\n",
    "        return img, hist\n",
    "\n",
    "    def _get_features(self, imgs_hists):\n",
    "        hists = [img_hist[1] for img_hist in imgs_hists]\n",
    "        features = []\n",
    "        for h in hists:\n",
    "            features.extend(h)\n",
    "        return hists\n",
    "\n",
    "\n",
    "class ViTEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        device,\n",
    "        model_name=\"google/vit-base-patch16-224\",\n",
    "        image_size=128,\n",
    "    ):\n",
    "        self.model_name = model_name\n",
    "        self.device = device\n",
    "        self.feature_extractor = ViTImageProcessor.from_pretrained(model_name)\n",
    "        self.model = ViTModel.from_pretrained(model_name, add_pooling_layer=False).to(\n",
    "            device\n",
    "        )\n",
    "        self.image_size = image_size\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"Extract features from images using ViT\"\"\"\n",
    "\n",
    "        X = list(X)\n",
    "\n",
    "        if not isinstance(X, list):\n",
    "            raise ValueError(\"Input is not a list of images.\")\n",
    "        elif not all(isinstance(x, np.ndarray) for x in X):\n",
    "            raise ValueError(\"Not all instances are numpy arrays (images).\")\n",
    "\n",
    "        inputs = self.feature_extractor(X, return_tensors=\"pt\").to(self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        return outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13ece0428364231a7030621c2b71abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Studies:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples = [(([pi[0] for pi in study[0]]), study[1]) for study in tqdm(studies, desc=\"Studies\")]\n",
    "df = pd.DataFrame(data=samples, columns=[\"features\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f331676401ff4b8a89b77dc470b3f1c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"features\"] = df[\"features\"].progress_apply(lambda images: np.mean(np.stack(images, axis=0), axis=0).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CVResult:\n",
    "    algo: str\n",
    "    encoder: str\n",
    "    test_acc: float\n",
    "    test_macro_prec: float\n",
    "    test_weighted_prec: float\n",
    "    test_macro_recall: float\n",
    "    test_weighted_recall: float\n",
    "    test_macro_f1: float\n",
    "    test_weighted_f1: float\n",
    "\n",
    "\n",
    "def _create_lbp_pipeline(clf: BaseEstimator) -> Pipeline:\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"encoder\", LBPEncoder()),\n",
    "            (\"clf\", clf),\n",
    "        ]\n",
    "    )\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def _create_vit_pipeline(clf: BaseEstimator) -> Pipeline:\n",
    "    pipeline = Pipeline([(\"encoder\", ViTEncoder(device=device)), (\"clf\", clf)])\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def _create_glcm_pipeline(clf: BaseEstimator) -> Pipeline:\n",
    "    pipeline = Pipeline([(\"encoder\", GLCMEncoder()), (\"clf\", clf)])\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def _create_zernike_moments_pipeline(clf: BaseEstimator) -> Pipeline:\n",
    "    pipeline = Pipeline([(\"encoder\", ZernikeMomentsEncoder()), (\"clf\", clf)])\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def _run_sklearn_cv(\n",
    "    clf: BaseEstimator | Pipeline,\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    cv: int,\n",
    "    random_state,\n",
    "    shuffle=True,\n",
    "):\n",
    "    \"\"\"Run the experiments using cross-validation.\"\"\"\n",
    "\n",
    "    ALGO_NAME_DICT = {\n",
    "        ExtraTreesClassifier: \"Extra Trees\",\n",
    "        DecisionTreeClassifier: \"Decision Tree\",\n",
    "        SVC: \"Support Vector\",\n",
    "        RandomForestClassifier: \"Random Forest\",\n",
    "        XGBClassifier: \"XGBoost\",\n",
    "        MLPClassifier: \"MLP\",\n",
    "    }\n",
    "\n",
    "    ENCODER_NAME_DICT = {\n",
    "        LBPEncoder: \"LBP\",\n",
    "        ViTEncoder: \"ViT\",\n",
    "        GLCMEncoder: \"GLCM\",\n",
    "        ZernikeMomentsEncoder: \"ZM\"\n",
    "    }\n",
    "\n",
    "    # Generate split\n",
    "    cv_results = []\n",
    "    skf = StratifiedKFold(n_splits=cv, random_state=random_state, shuffle=shuffle)\n",
    "    for train_index, test_index in skf.split(np.array(X), y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Resample the training data\n",
    "        X_train, y_train = RandomOverSampler(random_state=random_state).fit_resample(\n",
    "            pd.DataFrame(data=X_train), y_train\n",
    "        )\n",
    "        X_train = np.squeeze(X_train.to_numpy())\n",
    "\n",
    "        # Train model\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate model\n",
    "        y_pred = clf.predict(X_test)\n",
    "        cv_result = CVResult(\n",
    "            algo=ALGO_NAME_DICT[type(clf.named_steps[\"clf\"])],\n",
    "            encoder=ENCODER_NAME_DICT[type(clf.named_steps[\"encoder\"])],\n",
    "            test_acc=accuracy_score(y_test, y_pred),\n",
    "            test_macro_prec=precision_score(y_test, y_pred, average=\"macro\"),\n",
    "            test_weighted_prec=precision_score(y_test, y_pred, average=\"weighted\"),\n",
    "            test_macro_recall=recall_score(y_test, y_pred, average=\"macro\"),\n",
    "            test_weighted_recall=recall_score(y_test, y_pred, average=\"weighted\"),\n",
    "            test_macro_f1=f1_score(y_test, y_pred, average=\"macro\"),\n",
    "            test_weighted_f1=f1_score(y_test, y_pred, average=\"weighted\"),\n",
    "        )\n",
    "        cv_results.append(cv_result)\n",
    "\n",
    "    return cv_results\n",
    "\n",
    "\n",
    "def run_experiments(\n",
    "    clfs: list[BaseEstimator],\n",
    "    studies: pd.DataFrame,\n",
    "    cv: int,\n",
    "    random_state,\n",
    ") -> dict[str, list[np.ndarray]]:\n",
    "    \"\"\"Run experiments.\"\"\"\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    studies[\"labels\"] = label_encoder.fit_transform(studies[\"labels\"])\n",
    "\n",
    "    lbp_cv_results = [\n",
    "        _run_sklearn_cv(\n",
    "            _create_lbp_pipeline(clf),\n",
    "            np.array(studies[\"features\"]),\n",
    "            np.array(studies[\"labels\"]),\n",
    "            cv=cv,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "        for clf in tqdm(clfs, desc=\"LBP\")\n",
    "    ]\n",
    "\n",
    "    vit_cv_results = [\n",
    "        _run_sklearn_cv(\n",
    "            _create_vit_pipeline(clf),\n",
    "            np.array(studies[\"features\"]),\n",
    "            np.array(studies[\"labels\"]),\n",
    "            cv=cv,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "        for clf in tqdm(clfs, desc=\"ViT\")\n",
    "    ]\n",
    "\n",
    "    glcm_cv_results = [\n",
    "        _run_sklearn_cv(\n",
    "            _create_glcm_pipeline(clf),\n",
    "            np.array(studies[\"features\"]),\n",
    "            np.array(studies[\"labels\"]),\n",
    "            cv=cv,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "        for clf in tqdm(clfs, desc=\"GLCM\")\n",
    "    ]\n",
    "    \n",
    "    zernike_moments_cv_results = [\n",
    "        _run_sklearn_cv(\n",
    "            _create_zernike_moments_pipeline(clf),\n",
    "            np.array(studies[\"features\"]),\n",
    "            np.array(studies[\"labels\"]),\n",
    "            cv=cv,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "        for clf in tqdm(clfs, desc=\"ZM\")\n",
    "    ]\n",
    "\n",
    "    cv_result_list = [lbp_cv_results, vit_cv_results, glcm_cv_results, zernike_moments_cv_results]\n",
    "\n",
    "    return cv_result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "078ca94925a446af8abea5ee5ba4684c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LBP:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "089bc05298e6469eaba656f3ed041d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ViT:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10bda7bb65504a0db4eb63208662b847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GLCM:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e7f29f21fa94bc6b82772713bab2fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GLCM:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clfs = [\n",
    "    SVC(random_state=SEED),\n",
    "    RandomForestClassifier(random_state=SEED),\n",
    "    DecisionTreeClassifier(random_state=SEED),\n",
    "    ExtraTreesClassifier(random_state=SEED),\n",
    "    # XGBClassifier(\n",
    "    #     objective=\"multi:softprob\",\n",
    "    #     eval_metric=\"mlogloss\",\n",
    "    # ),\n",
    "    MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=SEED),\n",
    "]\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(action=\"ignore\", category=UndefinedMetricWarning)\n",
    "    warnings.simplefilter(action=\"ignore\", category=UserWarning)\n",
    "    warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "    cv_results_list = run_experiments(clfs, df, cv=CV, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo</th>\n",
       "      <th>encoder</th>\n",
       "      <th>acc</th>\n",
       "      <th>macro_prec</th>\n",
       "      <th>weighted_prec</th>\n",
       "      <th>macro_recall</th>\n",
       "      <th>weighted_recall</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>weighted_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Support Vector</td>\n",
       "      <td>LBP</td>\n",
       "      <td>0.707619</td>\n",
       "      <td>0.708901</td>\n",
       "      <td>0.712014</td>\n",
       "      <td>0.699747</td>\n",
       "      <td>0.707619</td>\n",
       "      <td>0.700581</td>\n",
       "      <td>0.706195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>LBP</td>\n",
       "      <td>0.637619</td>\n",
       "      <td>0.650803</td>\n",
       "      <td>0.650510</td>\n",
       "      <td>0.624495</td>\n",
       "      <td>0.637619</td>\n",
       "      <td>0.625034</td>\n",
       "      <td>0.632801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>LBP</td>\n",
       "      <td>0.518095</td>\n",
       "      <td>0.519722</td>\n",
       "      <td>0.528147</td>\n",
       "      <td>0.517424</td>\n",
       "      <td>0.518095</td>\n",
       "      <td>0.513604</td>\n",
       "      <td>0.518145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Extra Trees</td>\n",
       "      <td>LBP</td>\n",
       "      <td>0.695714</td>\n",
       "      <td>0.699963</td>\n",
       "      <td>0.698331</td>\n",
       "      <td>0.677399</td>\n",
       "      <td>0.695714</td>\n",
       "      <td>0.679612</td>\n",
       "      <td>0.688707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP</td>\n",
       "      <td>LBP</td>\n",
       "      <td>0.431429</td>\n",
       "      <td>0.215714</td>\n",
       "      <td>0.186469</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.431429</td>\n",
       "      <td>0.301281</td>\n",
       "      <td>0.260296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Support Vector</td>\n",
       "      <td>ViT</td>\n",
       "      <td>0.883810</td>\n",
       "      <td>0.888924</td>\n",
       "      <td>0.893847</td>\n",
       "      <td>0.885985</td>\n",
       "      <td>0.883810</td>\n",
       "      <td>0.882480</td>\n",
       "      <td>0.883919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>ViT</td>\n",
       "      <td>0.854286</td>\n",
       "      <td>0.859582</td>\n",
       "      <td>0.858376</td>\n",
       "      <td>0.845707</td>\n",
       "      <td>0.854286</td>\n",
       "      <td>0.849006</td>\n",
       "      <td>0.852973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>ViT</td>\n",
       "      <td>0.803333</td>\n",
       "      <td>0.828999</td>\n",
       "      <td>0.826245</td>\n",
       "      <td>0.789394</td>\n",
       "      <td>0.803333</td>\n",
       "      <td>0.786868</td>\n",
       "      <td>0.794011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Extra Trees</td>\n",
       "      <td>ViT</td>\n",
       "      <td>0.824286</td>\n",
       "      <td>0.832967</td>\n",
       "      <td>0.829592</td>\n",
       "      <td>0.812374</td>\n",
       "      <td>0.824286</td>\n",
       "      <td>0.817684</td>\n",
       "      <td>0.822294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MLP</td>\n",
       "      <td>ViT</td>\n",
       "      <td>0.863810</td>\n",
       "      <td>0.869580</td>\n",
       "      <td>0.875795</td>\n",
       "      <td>0.867803</td>\n",
       "      <td>0.863810</td>\n",
       "      <td>0.862895</td>\n",
       "      <td>0.864098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Support Vector</td>\n",
       "      <td>GLCM</td>\n",
       "      <td>0.684286</td>\n",
       "      <td>0.683668</td>\n",
       "      <td>0.685719</td>\n",
       "      <td>0.667677</td>\n",
       "      <td>0.684286</td>\n",
       "      <td>0.661464</td>\n",
       "      <td>0.671620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>GLCM</td>\n",
       "      <td>0.843333</td>\n",
       "      <td>0.841443</td>\n",
       "      <td>0.843150</td>\n",
       "      <td>0.838005</td>\n",
       "      <td>0.843333</td>\n",
       "      <td>0.838958</td>\n",
       "      <td>0.842502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>GLCM</td>\n",
       "      <td>0.714762</td>\n",
       "      <td>0.717738</td>\n",
       "      <td>0.724775</td>\n",
       "      <td>0.714899</td>\n",
       "      <td>0.714762</td>\n",
       "      <td>0.709733</td>\n",
       "      <td>0.713203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Extra Trees</td>\n",
       "      <td>GLCM</td>\n",
       "      <td>0.813810</td>\n",
       "      <td>0.811917</td>\n",
       "      <td>0.815214</td>\n",
       "      <td>0.809470</td>\n",
       "      <td>0.813810</td>\n",
       "      <td>0.809443</td>\n",
       "      <td>0.813323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MLP</td>\n",
       "      <td>GLCM</td>\n",
       "      <td>0.814762</td>\n",
       "      <td>0.817504</td>\n",
       "      <td>0.823204</td>\n",
       "      <td>0.814268</td>\n",
       "      <td>0.814762</td>\n",
       "      <td>0.811221</td>\n",
       "      <td>0.814306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Support Vector</td>\n",
       "      <td>ZM</td>\n",
       "      <td>0.658095</td>\n",
       "      <td>0.677552</td>\n",
       "      <td>0.671919</td>\n",
       "      <td>0.617929</td>\n",
       "      <td>0.658095</td>\n",
       "      <td>0.594644</td>\n",
       "      <td>0.615864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>ZM</td>\n",
       "      <td>0.567619</td>\n",
       "      <td>0.573917</td>\n",
       "      <td>0.585211</td>\n",
       "      <td>0.570833</td>\n",
       "      <td>0.567619</td>\n",
       "      <td>0.562863</td>\n",
       "      <td>0.566782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>ZM</td>\n",
       "      <td>0.558095</td>\n",
       "      <td>0.540815</td>\n",
       "      <td>0.549423</td>\n",
       "      <td>0.538510</td>\n",
       "      <td>0.558095</td>\n",
       "      <td>0.532899</td>\n",
       "      <td>0.547197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Extra Trees</td>\n",
       "      <td>ZM</td>\n",
       "      <td>0.558571</td>\n",
       "      <td>0.557498</td>\n",
       "      <td>0.569188</td>\n",
       "      <td>0.557702</td>\n",
       "      <td>0.558571</td>\n",
       "      <td>0.551018</td>\n",
       "      <td>0.557313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MLP</td>\n",
       "      <td>ZM</td>\n",
       "      <td>0.658095</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.658819</td>\n",
       "      <td>0.629672</td>\n",
       "      <td>0.658095</td>\n",
       "      <td>0.621163</td>\n",
       "      <td>0.636620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              algo encoder       acc  macro_prec  weighted_prec  macro_recall  \\\n",
       "0   Support Vector     LBP  0.707619    0.708901       0.712014      0.699747   \n",
       "1    Random Forest     LBP  0.637619    0.650803       0.650510      0.624495   \n",
       "2    Decision Tree     LBP  0.518095    0.519722       0.528147      0.517424   \n",
       "3      Extra Trees     LBP  0.695714    0.699963       0.698331      0.677399   \n",
       "4              MLP     LBP  0.431429    0.215714       0.186469      0.500000   \n",
       "5   Support Vector     ViT  0.883810    0.888924       0.893847      0.885985   \n",
       "6    Random Forest     ViT  0.854286    0.859582       0.858376      0.845707   \n",
       "7    Decision Tree     ViT  0.803333    0.828999       0.826245      0.789394   \n",
       "8      Extra Trees     ViT  0.824286    0.832967       0.829592      0.812374   \n",
       "9              MLP     ViT  0.863810    0.869580       0.875795      0.867803   \n",
       "10  Support Vector    GLCM  0.684286    0.683668       0.685719      0.667677   \n",
       "11   Random Forest    GLCM  0.843333    0.841443       0.843150      0.838005   \n",
       "12   Decision Tree    GLCM  0.714762    0.717738       0.724775      0.714899   \n",
       "13     Extra Trees    GLCM  0.813810    0.811917       0.815214      0.809470   \n",
       "14             MLP    GLCM  0.814762    0.817504       0.823204      0.814268   \n",
       "15  Support Vector      ZM  0.658095    0.677552       0.671919      0.617929   \n",
       "16   Random Forest      ZM  0.567619    0.573917       0.585211      0.570833   \n",
       "17   Decision Tree      ZM  0.558095    0.540815       0.549423      0.538510   \n",
       "18     Extra Trees      ZM  0.558571    0.557498       0.569188      0.557702   \n",
       "19             MLP      ZM  0.658095    0.658824       0.658819      0.629672   \n",
       "\n",
       "    weighted_recall  macro_f1  weighted_f1  \n",
       "0          0.707619  0.700581     0.706195  \n",
       "1          0.637619  0.625034     0.632801  \n",
       "2          0.518095  0.513604     0.518145  \n",
       "3          0.695714  0.679612     0.688707  \n",
       "4          0.431429  0.301281     0.260296  \n",
       "5          0.883810  0.882480     0.883919  \n",
       "6          0.854286  0.849006     0.852973  \n",
       "7          0.803333  0.786868     0.794011  \n",
       "8          0.824286  0.817684     0.822294  \n",
       "9          0.863810  0.862895     0.864098  \n",
       "10         0.684286  0.661464     0.671620  \n",
       "11         0.843333  0.838958     0.842502  \n",
       "12         0.714762  0.709733     0.713203  \n",
       "13         0.813810  0.809443     0.813323  \n",
       "14         0.814762  0.811221     0.814306  \n",
       "15         0.658095  0.594644     0.615864  \n",
       "16         0.567619  0.562863     0.566782  \n",
       "17         0.558095  0.532899     0.547197  \n",
       "18         0.558571  0.551018     0.557313  \n",
       "19         0.658095  0.621163     0.636620  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scores_to_df(cv_results_list: list[list[list[CVResult]]]) -> pd.DataFrame:\n",
    "    \"\"\"Transform the scores dictionary into a dataframe object.\"\"\"\n",
    "    data = []\n",
    "    for results_group in cv_results_list:\n",
    "        for cv_results in results_group:\n",
    "            data.append(\n",
    "                {\n",
    "                    \"algo\": cv_results[0].algo,\n",
    "                    \"encoder\": cv_results[0].encoder,\n",
    "                    \"acc\": np.mean([cv_result.test_acc for cv_result in cv_results]),\n",
    "                    \"macro_prec\": np.mean([cv_result.test_macro_prec for cv_result in cv_results]),\n",
    "                    \"weighted_prec\": np.mean([cv_result.test_weighted_prec for cv_result in cv_results]),\n",
    "                    \"macro_recall\": np.mean([cv_result.test_macro_recall for cv_result in cv_results]),\n",
    "                    \"weighted_recall\": np.mean([cv_result.test_weighted_recall for cv_result in cv_results]),\n",
    "                    \"macro_f1\": np.mean([cv_result.test_macro_f1 for cv_result in cv_results]),\n",
    "                    \"weighted_f1\": np.mean([cv_result.test_weighted_f1 for cv_result in cv_results]),\n",
    "                }\n",
    "            )\n",
    "    df = pd.DataFrame(data=data)\n",
    "    return df\n",
    "\n",
    "scores_to_df(cv_results_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ckd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
